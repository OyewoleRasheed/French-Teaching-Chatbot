{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:27:25.114664Z","iopub.execute_input":"2025-04-13T23:27:25.114898Z","iopub.status.idle":"2025-04-13T23:27:26.910622Z","shell.execute_reply.started":"2025-04-13T23:27:25.114876Z","shell.execute_reply":"2025-04-13T23:27:26.909846Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install transformers googletrans==4.0.0-rc1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:27:26.912012Z","iopub.execute_input":"2025-04-13T23:27:26.912298Z","iopub.status.idle":"2025-04-13T23:27:35.736718Z","shell.execute_reply.started":"2025-04-13T23:27:26.912275Z","shell.execute_reply":"2025-04-13T23:27:35.735783Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nCollecting googletrans==4.0.0-rc1\n  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.31)\nCollecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\nCollecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\nCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\nCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\nCollecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\nCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\nCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\nCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\nCollecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading httpx-0.13.3-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\nDownloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\nDownloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\nBuilding wheels for collected packages: googletrans\n  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=1edf791fb7db5ea66c4b79e94854e222c83b174ee9572c9538f0325f50e655e7\n  Stored in directory: /root/.cache/pip/wheels/39/17/6f/66a045ea3d168826074691b4b787b8f324d3f646d755443fda\nSuccessfully built googletrans\nInstalling collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n  Attempting uninstall: hyperframe\n    Found existing installation: hyperframe 6.1.0\n    Uninstalling hyperframe-6.1.0:\n      Successfully uninstalled hyperframe-6.1.0\n  Attempting uninstall: hpack\n    Found existing installation: hpack 4.1.0\n    Uninstalling hpack-4.1.0:\n      Successfully uninstalled hpack-4.1.0\n  Attempting uninstall: h11\n    Found existing installation: h11 0.14.0\n    Uninstalling h11-0.14.0:\n      Successfully uninstalled h11-0.14.0\n  Attempting uninstall: chardet\n    Found existing installation: chardet 5.2.0\n    Uninstalling chardet-5.2.0:\n      Successfully uninstalled chardet-5.2.0\n  Attempting uninstall: idna\n    Found existing installation: idna 3.10\n    Uninstalling idna-3.10:\n      Successfully uninstalled idna-3.10\n  Attempting uninstall: h2\n    Found existing installation: h2 4.2.0\n    Uninstalling h2-4.2.0:\n      Successfully uninstalled h2-4.2.0\n  Attempting uninstall: httpcore\n    Found existing installation: httpcore 1.0.7\n    Uninstalling httpcore-1.0.7:\n      Successfully uninstalled httpcore-1.0.7\n  Attempting uninstall: httpx\n    Found existing installation: httpx 0.28.1\n    Uninstalling httpx-0.28.1:\n      Successfully uninstalled httpx-0.28.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsigstore 3.6.1 requires rich~=13.0, but you have rich 14.0.0 which is incompatible.\ndatasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\nnilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\nopenai 1.61.1 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.2 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nlangsmith 0.3.8 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\ngoogle-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import MarianMTModel, MarianTokenizer\nfrom googletrans import Translator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:27:35.737902Z","iopub.execute_input":"2025-04-13T23:27:35.738167Z","iopub.status.idle":"2025-04-13T23:27:59.185016Z","shell.execute_reply.started":"2025-04-13T23:27:35.738139Z","shell.execute_reply":"2025-04-13T23:27:59.184236Z"}},"outputs":[{"name":"stderr","text":"2025-04-13 23:27:48.639430: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744586868.822716      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744586868.875585      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load translation model\ndef load_translation_model():\n    model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n    tokenizer = MarianTokenizer.from_pretrained(model_name)\n    model = MarianMTModel.from_pretrained(model_name)\n    return tokenizer, model\n\ntokenizer, model = load_translation_model()\ntranslator = Translator()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:27:59.185736Z","iopub.execute_input":"2025-04-13T23:27:59.186182Z","iopub.status.idle":"2025-04-13T23:28:03.460075Z","shell.execute_reply.started":"2025-04-13T23:27:59.186153Z","shell.execute_reply":"2025-04-13T23:28:03.459582Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d3942184b304e5ea9030b64606aba86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce8b1d7603ed4921a5cd3c1573caed5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3939592c1b3c40b9993cfdbd2e471b58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72108f51e5714be19b8438aaad7633aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3000699377a4901b38fe0c267a87574"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"795ab29fb9c04623ab7cbea048c7b544"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1614ee464d4c4b8df23bf59ed9bc73"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import torch\n\ndef translate_batch_to_french(text):\n    \"\"\"\n    Translates the given text into French.\n\n    Parameters:\n        text (str or list of str): The text(s) to be translated.\n\n    Returns:\n        str: The French translation, joined as a single string.\n    \"\"\"\n    # Use GPU if available\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    \n    # Ensure texts is a list\n    if isinstance(text, str):\n        texts = [text]\n    else:\n        texts = text\n    \n    # Tokenize the input texts\n    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n    inputs = {key: val.to(device) for key, val in inputs.items()}\n    \n    # Move the model to the appropriate device\n    model.to(device)\n    \n    # Generate translations\n    outputs = model.generate(**inputs)\n    \n    # Decode the generated tokens into strings\n    translations = [tokenizer.decode(t, skip_special_tokens=True) for t in outputs]\n    \n    # Join multiple translations into one string if necessary\n    return \" \".join(translations)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:40:09.215597Z","iopub.execute_input":"2025-04-13T23:40:09.215871Z","iopub.status.idle":"2025-04-13T23:40:09.221273Z","shell.execute_reply.started":"2025-04-13T23:40:09.215852Z","shell.execute_reply":"2025-04-13T23:40:09.220518Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def chatbot():\n    print(\"Bonjour! I am your French Teaching Chatbot. Ask me anything!\")\n    print(\"Examples: \\n- 'Translate I love apples'\\n- 'Teach me vocabulary'\\n- 'Explain French grammar'\\nType 'exit' to quit.\")\n    \n    while True:\n        user_input = input(\"You: \").strip()\n        if user_input.lower() == \"exit\":\n            print(\"Au revoir! Have a great day learning French!\")\n            break\n        \n        if \"translate\" in user_input.lower():\n            start = user_input.lower().find(\"translate\") + len(\"translate\")\n            english_text = user_input[start:].strip()\n            if not english_text:\n                english_text = user_input\n            french_translation = translate_batch_to_french(english_text)\n            print(\"Bot: Translation: \" + french_translation)\n        \n        elif \"vocabulary\" in user_input.lower():\n            print(\"Bot: Here are some basic French words:\")\n            print(\"1. Bonjour - Hello\")\n            print(\"2. Merci - Thank you\")\n            print(\"3. Oui - Yes\")\n            print(\"4. Non - No\")\n            print(\"5. Pomme - Apple\")\n        \n        elif \"grammar\" in user_input.lower():\n            print(\"Bot: Basic French Grammar:\")\n            print(\"- In French, adjectives agree with the noun in gender and number.\")\n            print(\"- Example: 'une pomme verte' (a green apple) vs. 'un chat noir' (a black cat).\")\n        \n        else:\n            french_translation = translate_batch_to_french(user_input)\n            print(\"Bot: Translation: \" + french_translation)\n\nif __name__ == \"__main__\":\n    chatbot()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T23:40:11.141486Z","iopub.execute_input":"2025-04-13T23:40:11.142311Z","iopub.status.idle":"2025-04-13T23:43:27.979137Z","shell.execute_reply.started":"2025-04-13T23:40:11.142285Z","shell.execute_reply":"2025-04-13T23:43:27.978335Z"}},"outputs":[{"name":"stdout","text":"Bonjour! I am your French Teaching Chatbot. Ask me anything!\nExamples: \n- 'Translate I love apples'\n- 'Teach me vocabulary'\n- 'Explain French grammar'\nType 'exit' to quit.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  good morning\n"},{"name":"stdout","text":"Bot: Translation: Bonjour.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  my name is Rasheed\n"},{"name":"stdout","text":"Bot: Translation: Mon nom est Rasheed\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  I am a student of UM6P\n"},{"name":"stdout","text":"Bot: Translation: Je suis un étudiant de UM6P\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  EXIT\n"},{"name":"stdout","text":"Au revoir! Have a great day learning French!\n","output_type":"stream"}],"execution_count":15}]}